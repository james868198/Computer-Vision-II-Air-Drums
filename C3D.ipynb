{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "airdrums",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ric31303/Computer-Vision-II-Air-Drums/blob/master/C3D.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NKidvp-wPfR4",
        "colab_type": "text"
      },
      "source": [
        "Computer-Vision-II-Air-Drums"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ty3HHZvVSfWl",
        "colab_type": "text"
      },
      "source": [
        "github: https://github.com/ric31303/Computer-Vision-II-Air-Drums.git"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DCXuGMKoPpoC",
        "colab_type": "code",
        "outputId": "5126c41c-6931-412d-9a7b-fa995dcd5714",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "!git clone https://github.com/ric31303/Computer-Vision-II-Air-Drums.git\n",
        "%ls"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'Computer-Vision-II-Air-Drums'...\n",
            "remote: Enumerating objects: 102, done.\u001b[K\n",
            "remote: Counting objects: 100% (102/102), done.\u001b[K\n",
            "remote: Compressing objects: 100% (62/62), done.\u001b[K\n",
            "remote: Total 102 (delta 45), reused 81 (delta 32), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (102/102), 24.45 KiB | 962.00 KiB/s, done.\n",
            "Resolving deltas: 100% (45/45), done.\n",
            "\u001b[0m\u001b[01;34mComputer-Vision-II-Air-Drums\u001b[0m/  \u001b[01;34msample_data\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b7H-t1zcHwrW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "%ls"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5g4gR8OcGZJu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "80ff971c-b1c9-49c2-8491-3d93894c4f98"
      },
      "source": [
        "%run Computer-Vision-II-Air-Drums/C3D.py"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Run CSD\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d3DEtW0VGxRG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "baddd3ed-8c12-48ec-ce7f-8e9b3d1b0b8e"
      },
      "source": [
        "# import pandas as pd\n",
        "import os\n",
        "# url = 'sample_data/california_housing_test.csv'\n",
        "# df1 = pd.read_csv(url)\n",
        "# print(df1)\n",
        "path = 'drive/My Drive/ML_DATA/input/'\n",
        "# entries = os.listdir(path)\n",
        "# print(entries)\n",
        "model = C3D(path) \n",
        "model.epoch_num = 50\n",
        "model.train()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[C3D][train] start\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:1817: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "INFO:tensorflow:Assets written to: models/C3M/assets\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv3d (Conv3D)              (None, 3, 222, 222, 64)   5248      \n",
            "_________________________________________________________________\n",
            "max_pooling3d (MaxPooling3D) (None, 3, 111, 111, 64)   0         \n",
            "_________________________________________________________________\n",
            "conv3d_1 (Conv3D)            (None, 1, 109, 109, 128)  221312    \n",
            "_________________________________________________________________\n",
            "max_pooling3d_1 (MaxPooling3 (None, 1, 54, 54, 128)    0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 373248)            0         \n",
            "_________________________________________________________________\n",
            "fc_layer1 (Dense)            (None, 64)                23887936  \n",
            "_________________________________________________________________\n",
            "fc_layer2 (Dense)            (None, 64)                4160      \n",
            "_________________________________________________________________\n",
            "fc_layer3 (Dense)            (None, 4)                 260       \n",
            "=================================================================\n",
            "Total params: 24,118,916\n",
            "Trainable params: 24,118,916\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "\n",
            "[C3D][getData] start...\n",
            "[generateBatchs]\n",
            "['d_0_b_l.mp4', 'd_0_b_r.mp4', 'd_0_m_l.mp4', 'd_0_m_r.mp4', 'd_0_t_r.mp4', 'd_0_t_l.mp4', 'd_1_t_l.mp4', 'd_1_t_r.mp4', 'd_1_m_r.mp4', 'd_1_m_l.mp4', 'd_1_b_l.mp4', 'd_1_b_r.mp4', 'd_2_b_r.mp4', 'd_2_b_l.mp4', 'd_2_m_l.mp4', 'd_2_m_r.mp4', 'd_2_t_l.mp4', 'd_2_t_r.mp4', '.DS_Store', 'labels']\n",
            "[generateBatchs] start parsing\n",
            "Sampled batches size: 265\n",
            "[generateBatchs] start parsing\n",
            "Sampled batches size: 265\n",
            "[generateBatchs] start parsing\n",
            "Sampled batches size: 174\n",
            "[generateBatchs] start parsing\n",
            "Sampled batches size: 174\n",
            "[generateBatchs] start parsing\n",
            "Sampled batches size: 207\n",
            "[generateBatchs] start parsing\n",
            "Sampled batches size: 207\n",
            "[generateBatchs] start parsing\n",
            "Sampled batches size: 290\n",
            "[generateBatchs] start parsing\n",
            "Sampled batches size: 290\n",
            "[generateBatchs] start parsing\n",
            "Sampled batches size: 283\n",
            "[generateBatchs] start parsing\n",
            "Sampled batches size: 283\n",
            "[generateBatchs] start parsing\n",
            "Sampled batches size: 141\n",
            "[generateBatchs] start parsing\n",
            "Sampled batches size: 141\n",
            "[generateBatchs] start parsing\n",
            "Sampled batches size: 238\n",
            "[generateBatchs] start parsing\n",
            "Sampled batches size: 238\n",
            "[generateBatchs] start parsing\n",
            "Sampled batches size: 232\n",
            "[generateBatchs] start parsing\n",
            "Sampled batches size: 232\n",
            "[generateBatchs] start parsing\n",
            "Sampled batches size: 257\n",
            "[generateBatchs] start parsing\n",
            "Sampled batches size: 257\n",
            "\n",
            "[C3D][getData] end...\n",
            "\n",
            "[C3D][train] training network...\n",
            "Epoch 1/50\n",
            "98/98 [==============================] - ETA: 0s - loss: 126.2828\n",
            "Epoch 00001: saving model to checkpoints/C3M/C3M_cp.ckpt\n",
            "98/98 [==============================] - 44s 445ms/step - loss: 126.2828 - val_loss: 1.2661\n",
            "Epoch 2/50\n",
            "98/98 [==============================] - ETA: 0s - loss: 2.6738\n",
            "Epoch 00002: saving model to checkpoints/C3M/C3M_cp.ckpt\n",
            "98/98 [==============================] - 42s 426ms/step - loss: 2.6738 - val_loss: 1.0607\n",
            "Epoch 3/50\n",
            "98/98 [==============================] - ETA: 0s - loss: 2.6202\n",
            "Epoch 00003: saving model to checkpoints/C3M/C3M_cp.ckpt\n",
            "98/98 [==============================] - 41s 423ms/step - loss: 2.6202 - val_loss: 0.9437\n",
            "Epoch 4/50\n",
            "98/98 [==============================] - ETA: 0s - loss: 2.6116\n",
            "Epoch 00004: saving model to checkpoints/C3M/C3M_cp.ckpt\n",
            "98/98 [==============================] - 41s 423ms/step - loss: 2.6116 - val_loss: 0.9223\n",
            "Epoch 5/50\n",
            "98/98 [==============================] - ETA: 0s - loss: 2.6113\n",
            "Epoch 00005: saving model to checkpoints/C3M/C3M_cp.ckpt\n",
            "98/98 [==============================] - 42s 424ms/step - loss: 2.6113 - val_loss: 0.9000\n",
            "Epoch 6/50\n",
            "98/98 [==============================] - ETA: 0s - loss: 2.6116\n",
            "Epoch 00006: saving model to checkpoints/C3M/C3M_cp.ckpt\n",
            "98/98 [==============================] - 42s 424ms/step - loss: 2.6116 - val_loss: 0.9136\n",
            "Epoch 7/50\n",
            "98/98 [==============================] - ETA: 0s - loss: 2.6113\n",
            "Epoch 00007: saving model to checkpoints/C3M/C3M_cp.ckpt\n",
            "98/98 [==============================] - 42s 424ms/step - loss: 2.6113 - val_loss: 0.9180\n",
            "\n",
            "[C3D][train] evaluating network...\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        None       0.90      1.00      0.95       936\n",
            "        fist       0.00      0.00      0.00        44\n",
            "  one finger       0.00      0.00      0.00        33\n",
            "       stick       0.00      0.00      0.00        31\n",
            "\n",
            "    accuracy                           0.90      1044\n",
            "   macro avg       0.22      0.25      0.24      1044\n",
            "weighted avg       0.80      0.90      0.85      1044\n",
            "\n",
            "[C3D][train] end\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}